{
  "feature_number": "005",
  "slug": "005-benchmark-scenario-generator",
  "friendly_name": "Benchmark Scenario Generator",
  "mission": "software-dev",
  "source_description": "benchmark scenarios. See @project-ideas.md idea 005. What's tricky is that... the last time I did this myself manually and it took a looot of time. 40 benchmarks took 4 days. This time I want to make LLMs generate it. So, create a system that would be able to generate those relatively easily. There will be a human-in-the-loop review. I'm not sure exactly how to do it, but I suppose for geometric consistency... the model that would generate it would generate a 2d matplotlib plots from top, side and bottom, and they must be actually consistent - the plots must match each other. Problems can vary in geometry that is presented, but also in goal objects. The area of the implementation is almost always defined as a box with length, height, width parameters. Problems can have small random 'forbid' zones appearing through the area to make it more challenging. Problems should be highly randomized - as much as possible. Start position, goal position, forbid zones present/missing (but within solvable range). I'v implemented this before and last time my major point of randomization was randomly reducing the goal/forbid zones by a random range of up to 40% and repositioning it within that bound. Maybe a good idea. Maybe something else can be done. [Clarifications: Python script output, XML verification final, no matplotlib, mesh exports required]",
  "created_at": "2026-02-01T10:00:00Z",
  "target_branch": "main",
  "vcs": "git"
}