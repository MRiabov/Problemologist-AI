{
  "runs": [
    {
      "timestamp": "2026-02-25T14:54:59.606951",
      "status": "passed",
      "total": 4,
      "passed": 4,
      "failed": 0,
      "skipped": 0,
      "errors": 0,
      "duration": 20.272,
      "tests": [
        {
          "name": "test_int_053_temporal_workflow_lifecycle",
          "classname": "tests.integration.architecture_p0.test_observability",
          "time": 6.321,
          "status": "passed",
          "message": null
        },
        {
          "name": "test_int_055_s3_artifact_upload_logging",
          "classname": "tests.integration.architecture_p0.test_observability",
          "time": 1.423,
          "status": "passed",
          "message": null
        },
        {
          "name": "test_int_054_temporal_failure_path",
          "classname": "tests.integration.architecture_p0.test_observability",
          "time": 3.728,
          "status": "passed",
          "message": null
        },
        {
          "name": "test_int_056_s3_upload_failure_retry",
          "classname": "tests.integration.architecture_p0.test_observability",
          "time": 1.34,
          "status": "passed",
          "message": null
        }
      ]
    },
    {
      "timestamp": "2026-02-25T14:53:55.231857",
      "status": "failed",
      "total": 5,
      "passed": 4,
      "failed": 1,
      "skipped": 0,
      "errors": 0,
      "duration": 321.609,
      "tests": [
        {
          "name": "test_int_004_episode_artifact_persistence",
          "classname": "tests.integration.architecture_p0.test_missing_p0",
          "time": 0.726,
          "status": "passed",
          "message": null
        },
        {
          "name": "test_int_005_trace_realtime_broadcast",
          "classname": "tests.integration.architecture_p0.test_missing_p0",
          "time": 5.209,
          "status": "passed",
          "message": null
        },
        {
          "name": "test_int_011_planner_target_caps_validation",
          "classname": "tests.integration.architecture_p0.test_missing_p0",
          "time": 0.142,
          "status": "passed",
          "message": null
        },
        {
          "name": "test_int_014_cots_propagation",
          "classname": "tests.integration.architecture_p0.test_missing_p0",
          "time": 5.473,
          "status": "passed",
          "message": null
        },
        {
          "name": "test_int_025_events_collection_e2e",
          "classname": "tests.integration.architecture_p0.test_missing_p0",
          "time": 302.467,
          "status": "failed",
          "message": "@pytest.mark.integration_p0\n    @pytest.mark.asyncio\n    async def test_int_025_events_collection_e2e():\n        \"\"\"INT-025: Verify worker events are ingested and persisted as traces.\"\"\"\n        async with httpx.AsyncClient(timeout=300.0) as client:\n            session_id = f\"INT-025-{uuid.uuid4().hex[:8]}\"\n            run_req = AgentRunRequest(task=\"Run a simulation\", session_id=session_id)\n            run_resp = await client.post(\n                f\"{CONTROLLER_URL}/agent/run\",\n                json=run_req.model_dump(mode=\"json\"),\n            )\n            assert run_resp.status_code == 202\n            run_data = AgentRunResponse.model_validate(run_resp.json())\n            episode_id = run_data.episode_id\n    \n            # Wait for completion\n            max_attempts = 60\n            for _ in range(max_attempts):\n                await asyncio.sleep(5.0)\n                status_resp = await client.get(f\"{CONTROLLER_URL}/episodes/{episode_id}\")\n                ep_data = EpisodeResponse.model_validate(status_resp.json())\n                if ep_data.status == EpisodeStatus.COMPLETED:\n                    break\n            else:\n>               pytest.fail(\"Agent did not complete simulation task in time\")\nE               Failed: Agent did not complete simulation task in time\n\ntests/integration/architecture_p0/test_missing_p0.py:196: Failed"
        }
      ]
    },
    {
      "timestamp": "2026-02-25T14:25:34.094957",
      "status": "failed",
      "total": 2,
      "passed": 0,
      "failed": 0,
      "skipped": 0,
      "errors": 2,
      "duration": 9.105,
      "tests": [
        {
          "name": "tests.integration.architecture_p0.test_missing_p0",
          "classname": "",
          "time": 0.0,
          "status": "error",
          "message": "ImportError while importing test module '/app/tests/integration/architecture_p0/test_missing_p0.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/home/jules/.pyenv/versions/3.12.12/lib/python3.12/importlib/__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/integration/architecture_p0/test_missing_p0.py:8: in <module>\n    from controller.api.schemas import (\nE   ImportError: cannot import name 'TestEpisodeCreateResponse' from 'controller.api.schemas' (/app/controller/api/schemas.py)"
        },
        {
          "name": "tests.integration.architecture_p0.test_observability",
          "classname": "",
          "time": 0.0,
          "status": "error",
          "message": "ImportError while importing test module '/app/tests/integration/architecture_p0/test_observability.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/home/jules/.pyenv/versions/3.12.12/lib/python3.12/importlib/__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/integration/architecture_p0/test_observability.py:8: in <module>\n    from controller.api.schemas import (\nE   ImportError: cannot import name 'TestEpisodeCreateResponse' from 'controller.api.schemas' (/app/controller/api/schemas.py)"
        }
      ]
    },
    {
      "timestamp": "2026-02-25T14:24:34.529095",
      "status": "passed",
      "total": 1,
      "passed": 1,
      "failed": 0,
      "skipped": 0,
      "errors": 0,
      "duration": 95.044,
      "tests": [
        {
          "name": "test_int_110_gpu_oom_retry",
          "classname": "tests.integration.architecture_p0.test_int_110_gpu_oom",
          "time": 94.757,
          "status": "passed",
          "message": null
        }
      ]
    },
    {
      "timestamp": "2026-02-25T08:12:01.841080",
      "status": "failed",
      "total": 1,
      "passed": 0,
      "failed": 1,
      "skipped": 0,
      "errors": 0,
      "duration": 126.378,
      "tests": [
        {
          "name": "test_code_viewer_line_selection_and_mentions[chromium]",
          "classname": "tests.integration.frontend.test_int_164",
          "time": 126.106,
          "status": "failed",
          "message": "page = <Page url='http://localhost:15173/benchmark'>\n\n    @pytest.mark.integration_frontend\n    def test_code_viewer_line_selection_and_mentions(page: Page):\n        # 1. Navigate to the local development server\n        page.goto(\"http://localhost:15173\", timeout=60000)\n    \n        # 2. Navigate to the Benchmark page\n        benchmark_link = page.get_by_role(\"link\", name=\"Benchmark\")\n        expect(benchmark_link).to_be_visible(timeout=30000)\n        benchmark_link.click()\n    \n        # 3. Click \"CREATE NEW\" button\n        create_new_button = page.get_by_role(\"button\", name=\"CREATE NEW\")\n        expect(create_new_button).to_be_visible(timeout=30000)\n        create_new_button.click()\n    \n        # 4. Enter the prompt\n        prompt_text = \"Create a simple benchmark for moving a ball.\"\n        prompt_input = page.locator(\"#chat-input\")\n        expect(prompt_input).to_be_visible(timeout=30000)\n        prompt_input.fill(prompt_text)\n    \n        # 5. Submit the prompt\n        send_button = page.get_by_label(\"Send Message\")\n        expect(send_button).to_be_enabled(timeout=30000)\n        send_button.click()\n    \n        # 6. Wait for the \"Confirm & Start\" button to appear and click it\n        confirm_button = page.get_by_role(\"button\", name=\"Confirm & Start\")\n>       expect(confirm_button).to_be_visible(timeout=120000)\nE       AssertionError: Locator expected to be visible\nE       Actual value: None\nE       Error: element(s) not found \nE       Call log:\nE         - Expect \"to_be_visible\" with timeout 120000ms\nE         - waiting for get_by_role(\"button\", name=\"Confirm & Start\")\n\ntests/integration/frontend/test_int_164.py:32: AssertionError"
        }
      ]
    }
  ]
}